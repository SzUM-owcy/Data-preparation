{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omOHwnIkDwWs",
        "outputId": "1473022c-8909-4bb3-a15d-4dbddd8aec96"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create directory for data\n",
        "!mkdir data\n",
        "\n",
        "# unzip files from zip folder\n",
        "!unzip \"/content/drive/MyDrive/szum_splits/split1\" -d \"data/\""
      ],
      "metadata": {
        "id": "HYWiBHEFEMG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Python program to create\n",
        "# Image Classifier using CNN\n",
        "\n",
        "# Importing the required libraries\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from random import shuffle\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "5A2eGPhBFIP4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Setting up the env'''\n",
        "\n",
        "TRAIN_DIR = 'data/split1/train'\n",
        "TEST_DIR = 'data/split1/val'\n",
        "IMG_SIZE = (3982, 2700)  # Size of the image\n",
        "LR = 1e-3\n",
        "\n",
        "'''Setting up the model which will help with tensorflow models'''\n",
        "MODEL_NAME = 'plants-detection-{}-{}.model'.format(LR, '6conv-basic')"
      ],
      "metadata": {
        "id": "vWynRjm0RFHI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Creating the training data'''\n",
        "def create_train_data():\n",
        "    # Creating an empty list where we should store the training data\n",
        "    # after a little preprocessing of the data\n",
        "    training_data = []\n",
        "\n",
        "    # tqdm is only used for interactive loading\n",
        "    # loading the training data\n",
        "    for label in os.listdir(TRAIN_DIR):\n",
        "        path = os.path.join(TRAIN_DIR, label)\n",
        "        print(\"label:\", label)\n",
        "        print(\"path:\", path)\n",
        "        for img in tqdm(os.listdir(path)):\n",
        "            # print(\"img:\", img)\n",
        "            # labeling the images\n",
        "            label = path.split('/')[-1]\n",
        "\n",
        "            img_path = os.path.join(TRAIN_DIR, img)\n",
        "\n",
        "            # loading the image from the path and then converting them into\n",
        "            # grayscale for easier covnet prob\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "            # final step-forming the training data list with numpy array of the images\n",
        "            training_data.append([np.array(img), np.array(label)])\n",
        "\n",
        "    # shuffling of the training data to preserve the random state of our data\n",
        "    shuffle(training_data)\n",
        "\n",
        "    # saving our trained data for further uses if required\n",
        "    np.save('train_data.npy', training_data)\n",
        "    return training_data\n",
        "\n",
        "'''Processing the given test data'''\n",
        "# Almost same as processing the training data but\n",
        "# we dont have to label it.\n",
        "def process_test_data():\n",
        "    testing_data = []\n",
        "    for label in os.listdir(TEST_DIR):\n",
        "        path = os.path.join(TEST_DIR, label)\n",
        "        print(\"label:\", label)\n",
        "        print(\"path:\", path)\n",
        "        for img in tqdm(os.listdir(path)):\n",
        "            img_num = img.split('.')[0]\n",
        "            path = os.path.join(TEST_DIR, img)\n",
        "            img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "            testing_data.append([np.array(img), img_num])\n",
        "\n",
        "    shuffle(testing_data)\n",
        "    np.save('test_data.npy', testing_data)\n",
        "    return testing_data\n",
        "\n",
        "'''Running the training and the testing in the dataset for our model'''\n",
        "train_data = create_train_data()\n",
        "test_data = process_test_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cy02rwcVSiRZ",
        "outputId": "4598731e-e254-45f7-ca03-6290d53b2119"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label: Rust\n",
            "path: data/split1/train/Rust\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 403/403 [00:00<00:00, 24012.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label: Powdery\n",
            "path: data/split1/train/Powdery\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [00:00<00:00, 7096.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label: Healthy\n",
            "path: data/split1/train/Healthy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 422/422 [00:00<00:00, 10449.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label:"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Rust\n",
            "path: data/split1/val/Rust\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:00<00:00, 27377.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label: Powdery\n",
            "path: data/split1/val/Powdery\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:00<00:00, 31385.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label: Healthy\n",
            "path: data/split1/val/Healthy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 53/53 [00:00<00:00, 4397.76it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ucdqMyTHWitW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}