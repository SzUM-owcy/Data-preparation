{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import train, validation, and test datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_normalize = ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "test_normalize = ImageDataGenerator(rescale=1./255)\n",
    "val_normalize = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "main_dir = 'splits/split1/'\n",
    "train_set = train_normalize.flow_from_directory(directory=main_dir+\"train\",target_size=(225,225),class_mode='categorical')\n",
    "val_set = val_normalize.flow_from_directory(directory=main_dir+\"val\",target_size=(225,225),class_mode=\"categorical\")\n",
    "test_set = test_normalize.flow_from_directory(directory=main_dir+\"test\",target_size=(225,225),class_mode=\"categorical\")"
   ],
   "metadata": {
    "id": "MyxXFNQmDVPq"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create, train, and validate the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Flatten,Dense,MaxPooling2D,Conv2D,Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "# !pip install tensorflow-addons\n",
    "# import tensorflow_addons as tfa\n",
    "\n",
    "\n",
    "\n",
    "# ########## Good architecture\n",
    "\n",
    "learning_rate = 0.001\n",
    "epochs = 15\n",
    "batch_size = 16\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), input_shape=(fig_size, fig_size, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "opt = Adam(learning_rate=learning_rate)\n",
    "checkpoint_path = \"gdfit_1_20e_16b-{epoch:1d}.h5\"\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,  # Save only the weights\n",
    "    save_freq='epoch' # Save for every epoch\n",
    ")\n",
    "\n",
    "\n",
    "# ########## Overfit architecture\n",
    "# learning_rate = 0.001\n",
    "# epochs = 30\n",
    "# batch_size = 16\n",
    "# model = Sequential()\n",
    "# model.add(Conv2D(64, (3, 3), input_shape=(fig_size, fig_size, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "# model.add(Conv2D(128, (3, 3), activation='relu'))  # Additional convolutional layer\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(512, activation='relu'))  # Increased neurons\n",
    "# model.add(Dense(256, activation='relu'))  # Increased neurons\n",
    "# model.add(Dense(128, activation='relu'))  # Increased neurons\n",
    "# model.add(Dense(64, activation='relu'))  # Increased neurons\n",
    "# model.add(Dense(32, activation='relu'))  # Increased neurons\n",
    "# model.add(Dense(3, activation='softmax'))\n",
    "# opt = Adam(learning_rate=learning_rate)\n",
    "# checkpoint_path = \"ovfit_1_30e_16b-{epoch:1d}.h5\"\n",
    "# checkpoint_callback = ModelCheckpoint(\n",
    "#     filepath=checkpoint_path,\n",
    "#     save_freq='epoch' # Save for every epoch\n",
    "# )\n",
    "\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model with adjusted parameters\n",
    "history = model.fit(train_set, epochs=epochs, batch_size=batch_size, validation_data=val_set, callbacks=[checkpoint_callback])\n",
    "# history = model.fit(train_set, epochs=epochs, batch_size=batch_size, validation_data=val_set)\n"
   ],
   "metadata": {
    "id": "_mB1HnCuCiVW"
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plot architecture of created model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "plot_model(model,show_layer_names=True,show_shapes=True)"
   ],
   "metadata": {
    "id": "iPKWmeZfCiX7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plot Training and Validation Accuracy and Loss"
   ],
   "metadata": {
    "id": "9IrfpIU-CjD_",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Custom tick formatter function\n",
    "def format_tick(x, pos):\n",
    "    return int(x + 1)\n",
    "# Plot training accuracy and loss\n",
    "plt.figure(figsize=(12, 6), constrained_layout=True)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy', color='red')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='blue')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.grid(True)  # Add grid\n",
    "plt.xticks(range(0, epochs+1))  # Set x-axis ticks to every integer value\n",
    "plt.gca().xaxis.set_major_formatter(plt.FuncFormatter(format_tick))  # Apply custom tick formatter\n",
    "plt.tight_layout()  # Adjust layout\n",
    "plt.legend()\n",
    "\n",
    "# Plot validation accuracy and loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss', color='red')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss', color='blue')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)  # Add grid\n",
    "plt.xticks(range(0, epochs+1))  # Set x-axis ticks to every integer value\n",
    "plt.gca().xaxis.set_major_formatter(plt.FuncFormatter(format_tick))  # Apply custom tick formatterplt.tight_layout()  # Adjust layout\n",
    "plt.show()\n",
    "plt.tight_layout(pad=5.0)\n",
    "plt.subplots_adjust(left=0.1, bottom=0.1,                    top=0.9, wspace=0.4,hspace=0.4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Metrics - using TP, FP, TN, FN - not tested"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def perf_measure(y_actual, y_pred):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_actual[i]==y_pred[i]==1:\n",
    "           TP += 1\n",
    "        if y_pred[i]==1 and y_actual[i]!=y_pred[i]:\n",
    "           FP += 1\n",
    "        if y_actual[i]==y_pred[i]==0:\n",
    "           TN += 1\n",
    "        if y_pred[i]==0 and y_actual[i]!=y_pred[i]:\n",
    "           FN += 1\n",
    "\n",
    "    return(TP, FP, TN, FN)\n",
    "\n",
    "def calculate_accuracy(tp, fp, tn, fn):\n",
    "    return (tp + tn) / (tp + fp + tn + fn)\n",
    "\n",
    "def calculate_recall(tp, fp, tn, fn):\n",
    "    if (tp+fn) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "      return tp / (tp + fn)\n",
    "\n",
    "def calculate_precision(tp, fp, tn, fn):\n",
    "    if (tp+fp) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return tp / (tp + fp)\n",
    "\n",
    "def calculate_f1_score(tp, fp, tn, fn):\n",
    "    precision = calculate_precision(tp, fp, tn, fn)\n",
    "    recall = calculate_recall(tp, fp, tn, fn)\n",
    "    denominator = precision + recall\n",
    "    if denominator == 0:\n",
    "      return 0\n",
    "    else:\n",
    "      return 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "# Lists to store metrics for each epoch\n",
    "val_accuracy_list, val_recall_list, val_precision_list, val_f1_list = [], [], [], []\n",
    "\n",
    "i_begin = 1\n",
    "i_end = epochs + 1\n",
    "model_name = \"gdfit_1_20e_16b\"\n",
    "# Load each saved model and calculate evaluation metrics\n",
    "for epoch in range(i_begin, i_end):  # Assuming you trained for 10 epochs\n",
    "    print(\"epoch:\", epoch)\n",
    "    # Load model from saved checkpoint\n",
    "    model.load_weights(model_name + f\"-{epoch}.h5\")\n",
    "\n",
    "    # Make predictions on validation dataset\n",
    "    val_predictions = model.predict(val_set)\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    true_labels = val_set.classes\n",
    "    predicted_labels = np.argmax(val_predictions, axis=1)\n",
    "\n",
    "    # Extract true positives, false positives, true negatives, and false negatives\n",
    "    tp, fp, tn, fn = perf_measure(true_labels, predicted_labels)\n",
    "    print(\"tp:\", tp, \" fp:\", fp, \"tn:\", tn, \"fn:\", fn)\n",
    "\n",
    "    # Calculate metrics based on TP, FP, TN, FN\n",
    "    val_accuracy = calculate_accuracy(tp, fp, tn, fn)\n",
    "    print(\"val_accuracy:\", val_accuracy)\n",
    "    val_recall = calculate_recall(tp, fp, tn, fn)\n",
    "    print(\"val_recall:\", val_recall)\n",
    "    val_precision = calculate_precision(tp, fp, tn, fn)\n",
    "    print(\"val_precision:\", val_precision)\n",
    "    val_f1 = calculate_f1_score(tp, fp, tn, fn)\n",
    "    print(\"val_f1:\", val_f1)\n",
    "\n",
    "    # Append metrics to lists\n",
    "    val_accuracy_list.append(val_accuracy)\n",
    "    val_recall_list.append(val_recall)\n",
    "    val_precision_list.append(val_precision)\n",
    "    val_f1_list.append(val_f1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Metrics using scikit-learn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "\n",
    "# Lists to store metrics for each epoch\n",
    "val_accuracy_list, val_recall_list, val_precision_list, val_f1_list = [], [], [], []\n",
    "\n",
    "i_begin = 1\n",
    "i_end = epochs + 1\n",
    "model_name = \"gdfit_1_20e_16b\"\n",
    "\n",
    "# Load each saved model and calculate evaluation metrics\n",
    "for epoch in range(i_begin, i_end):  # Assuming you trained for 10 epochs\n",
    "    print(\"epoch:\", epoch)\n",
    "    # Load model from saved checkpoint\n",
    "    model.load_weights(model_name + f\"-{epoch}.h5\")\n",
    "\n",
    "    # Make predictions on validation dataset\n",
    "    val_predictions = model.predict(val_set)\n",
    "\n",
    "    # print(val_predictions)\n",
    "\n",
    "    # Convert predictions to class labels\n",
    "    predicted_labels = np.argmax(val_predictions, axis=1)\n",
    "\n",
    "    # print(predicted_labels)\n",
    "\n",
    "    # print(val_set.classes)\n",
    "    # print(predicted_labels)\n",
    "\n",
    "    # Calculate metrics based on confusion matrix\n",
    "    val_accuracy = accuracy_score(val_set.classes, predicted_labels)\n",
    "    val_recall = recall_score(val_set.classes, predicted_labels, average='macro')\n",
    "    val_precision = precision_score(val_set.classes, predicted_labels, average='macro')\n",
    "    val_f1 = f1_score(val_set.classes, predicted_labels, average='macro')\n",
    "\n",
    "    # Append metrics to lists\n",
    "    val_accuracy_list.append(val_accuracy)\n",
    "    val_recall_list.append(val_recall)\n",
    "    val_precision_list.append(val_precision)\n",
    "    val_f1_list.append(val_f1)\n",
    "\n",
    "    print(\"val_accuracy:\", val_accuracy)\n",
    "    print(\"val_recall:\", val_recall)\n",
    "    print(\"val_precision:\", val_precision)\n",
    "    print(\"val_f1:\", val_f1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plot metrics for each epoch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot metrics for each epoch\n",
    "plt.figure(figsize=(8, 6))  # Adjust figure size if needed\n",
    "\n",
    "colors = [\"orange\", \"green\", \"purple\", \"blue\"]\n",
    "\n",
    "# Plot accuracy for each epoch\n",
    "plt.plot(range(i_begin, i_end), val_accuracy_list, color=colors[0], label=\"Accuracy\")\n",
    "plt.plot(range(i_begin, i_end), val_recall_list, color=colors[1], label=\"Recall\")\n",
    "plt.plot(range(i_begin, i_end), val_precision_list, color=colors[2], label=\"Precision\")\n",
    "plt.plot(range(i_begin, i_end), val_f1_list, color=colors[3], label=\"F1 Score\")\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Metric value')\n",
    "plt.title('Validation Metrics over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)  # Add grid\n",
    "plt.xticks(range(i_begin, i_end))  # Set x-axis ticks to every integer value\n",
    "plt.tight_layout()  # Adjust layout\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plot Confusion Matrix for every 5th epoch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Define a function to plot confusion matrix\n",
    "def plot_confusion_matrix(matrix, title, ax, class_names):\n",
    "    sns.heatmap(matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names, ax=ax)\n",
    "    ax.set_xlabel('Predicted labels')\n",
    "    ax.set_ylabel('True labels')\n",
    "    ax.set_title(title, fontsize=10)\n",
    "\n",
    "\n",
    "# Get the class names from the generator\n",
    "class_names = list(val_set.class_indices.keys())\n",
    "\n",
    "for epoch in range(i_begin, i_end):\n",
    "    if epoch % 5 == 0:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))  # Adjust the width of the figure\n",
    "        # fig.subplots_adjust(wspace=0.5)  # Adjust the horizontal space between subplots\n",
    "\n",
    "        # Load the model weights from the checkpoint file for this epoch\n",
    "        model.load_weights(model_name + f\"-{epoch}.h5\")\n",
    "\n",
    "        # Get the predictions for the training and validation datasets\n",
    "        train_predictions = model.predict(train_set)\n",
    "        val_predictions = model.predict(val_set)\n",
    "\n",
    "        # Get the true labels for the training and validation datasets\n",
    "        train_true_labels = train_set.classes\n",
    "        val_true_labels = val_set.classes\n",
    "\n",
    "        # Calculate accuracy\n",
    "        train_accuracy = accuracy_score(train_true_labels, np.argmax(train_predictions, axis=1))\n",
    "        val_accuracy = accuracy_score(val_true_labels, np.argmax(val_predictions, axis=1))\n",
    "        print(\"train_accuracy:\", train_accuracy)\n",
    "        print(\"val_accuracy:\", val_accuracy)\n",
    "\n",
    "        # Compute confusion matrix for training and validation datasets\n",
    "        train_conf_matrix = confusion_matrix(train_true_labels, np.argmax(train_predictions, axis=1))\n",
    "        val_conf_matrix = confusion_matrix(val_true_labels, np.argmax(val_predictions, axis=1))\n",
    "\n",
    "        # Plot confusion matrices side by side\n",
    "        fig.suptitle(f'Confusion Matrices (Epoch {epoch})')\n",
    "        plot_confusion_matrix(train_conf_matrix, f'Training Confusion Matrix (Epoch {epoch})', ax1, class_names)\n",
    "        plot_confusion_matrix(val_conf_matrix, f'Validation Confusion Matrix (Epoch {epoch})', ax2, class_names)\n",
    "        plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}