{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "omOHwnIkDwWs",
    "outputId": "c46da2fc-e0fc-4e6d-cae7-030df3e23d04"
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# create directory for data\n",
    "!mkdir splits\n",
    "\n",
    "# unzip files from zip folder\n",
    "!unzip \"/content/drive/MyDrive/szum_splits/split1\" -d \"splits/\""
   ],
   "metadata": {
    "id": "HYWiBHEFEMG6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os"
   ],
   "metadata": {
    "id": "McGVSyfFCiAY"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gQZCO2-YFTNZ",
    "outputId": "b201ddb4-a118-4afe-872f-82f1889ca654"
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_normalize = ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "test_normalize = ImageDataGenerator(rescale=1./255)\n",
    "val_normalize = ImageDataGenerator(rescale=1./255)"
   ],
   "metadata": {
    "id": "MyxXFNQmDVPq"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "main_dir = 'splits/split1/'\n",
    "train_set = train_normalize.flow_from_directory(directory=main_dir+\"train\",target_size=(225,225),class_mode='categorical')\n",
    "val_set = val_normalize.flow_from_directory(directory=main_dir+\"val\",target_size=(225,225),class_mode=\"categorical\")\n",
    "test_set = test_normalize.flow_from_directory(directory=main_dir+\"test\",target_size=(225,225),class_mode=\"categorical\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dXgCs-AYCiKj",
    "outputId": "fb318d15-5e49-467c-a1b2-be9774d9f4e1"
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 1225 images belonging to 3 classes.\n",
      "Found 153 images belonging to 3 classes.\n",
      "Found 153 images belonging to 3 classes.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Flatten,Dense,MaxPooling2D,Conv2D,Dropout"
   ],
   "metadata": {
    "id": "KAKRd0fFCiTI"
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64,(3,3),input_shape=(225,225,3),activation='relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(128,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3,activation='softmax'))"
   ],
   "metadata": {
    "id": "_mB1HnCuCiVW"
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plot_model(model,show_layer_names=True,show_shapes=True)"
   ],
   "metadata": {
    "id": "iPKWmeZfCiX7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ],
   "metadata": {
    "id": "j9TLc-R9D9z-"
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "history = model.fit(train_set, epochs=9, batch_size=16, validation_data=test_set, callbacks=[early_stopping])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dSA-Tu5nD936",
    "outputId": "45505265-e40d-4d50-8314-190413b0e5c9"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/9\n",
      "39/39 [==============================] - 99s 2s/step - loss: 1.6934 - accuracy: 0.4506 - val_loss: 0.7823 - val_accuracy: 0.7320\n",
      "Epoch 2/9\n",
      "39/39 [==============================] - 99s 3s/step - loss: 0.7016 - accuracy: 0.6727 - val_loss: 0.6620 - val_accuracy: 0.6928\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot()\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "rpmQX8n9D96Y"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.evaluate(val_set)\n",
    "model.evaluate(test_set)\n"
   ],
   "metadata": {
    "id": "ZMiORIgUCiaF"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Confusion Matrix"
   ],
   "metadata": {
    "id": "9IrfpIU-CjD_",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Step 1: Make Predictions\n",
    "predictions = model.predict(val_set)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Get true labels\n",
    "true_labels = val_set.classes\n",
    "\n",
    "# Step 2: Compute Confusion Matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Step 3: Visualize Confusion Matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=val_set.class_indices, yticklabels=val_set.class_indices)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "Make predictions on the test set "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_predictions = model.predict(test_set)\n",
    "test_predicted_labels = np.argmax(test_predictions, axis=1)\n",
    "test_true_labels = test_set.classes\n",
    "\n",
    "# Compute confusion matrix for the test set\n",
    "test_conf_matrix = confusion_matrix(test_true_labels, test_predicted_labels)\n",
    "\n",
    "# Extract true positives, false positives, true negatives, and false negatives for each class\n",
    "for i in range(test_conf_matrix.shape[0]):\n",
    "    tn, fp, fn, tp = test_conf_matrix[i, 0], test_conf_matrix[i, 1], test_conf_matrix[i, 2], np.sum(test_conf_matrix[i]) - test_conf_matrix[i, i]\n",
    "    print(f\"For class {i}:\")\n",
    "    print(\"True Negatives:\", tn)\n",
    "    print(\"False Positives:\", fp)\n",
    "    print(\"False Negatives:\", fn)\n",
    "    print(\"True Positives:\", tp)\n",
    "    print()\n",
    "\n",
    "# Calculate true positives, false positives, true negatives, and false negatives for all classes\n",
    "tn_all = test_conf_matrix[0, 0]\n",
    "fp_all = test_conf_matrix[0, 1]\n",
    "fn_all = test_conf_matrix[0, 2]\n",
    "tp_all = np.sum(test_conf_matrix[0]) - test_conf_matrix[0, 0]\n",
    "for i in range(1, test_conf_matrix.shape[0]):\n",
    "    tn_all += test_conf_matrix[i, 0]\n",
    "    fp_all += test_conf_matrix[i, 1]\n",
    "    fn_all += test_conf_matrix[i, 2]\n",
    "    tp_all += np.sum(test_conf_matrix[i]) - test_conf_matrix[i, i]\n",
    "\n",
    "print(\"All Classes Combined:\")\n",
    "print(\"True Negatives:\", tn_all)\n",
    "print(\"False Positives:\", fp_all)\n",
    "print(\"False Negatives:\", fn_all)\n",
    "print(\"True Positives:\", tp_all)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "raw",
   "source": [
    "Calculate metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "def calculate_accuracy(tp, fp, tn, fn):\n",
    "    return (tp + tn) / (tp + fp + tn + fn)\n",
    "\n",
    "def calculate_recall(tp, fp, tn, fn):\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "def calculate_precision(tp, fp, tn, fn):\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "def calculate_f1_score(tp, fp, tn, fn):\n",
    "    precision = calculate_precision(tp, fp, tn, fn)\n",
    "    recall = calculate_recall(tp, fp, tn, fn)\n",
    "    return 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "def calculate_auc(tp, fp, tn, fn):\n",
    "    return roc_auc_score([0, 1], [0, 1], sample_weight=[tn+fp, fn+tp])\n",
    "\n",
    "# Example usage:\n",
    "tn, fp, fn, tp = 100, 10, 5, 85\n",
    "\n",
    "accuracy = calculate_accuracy(tp, fp, tn, fn)\n",
    "recall = calculate_recall(tp, fp, tn, fn)\n",
    "precision = calculate_precision(tp, fp, tn, fn)\n",
    "f1score = calculate_f1_score(tp, fp, tn, fn)\n",
    "auc = calculate_auc(tp, fp, tn, fn)\n",
    "\n",
    "print(\"Accuracy:\", round(accuracy, 3))\n",
    "print(\"Recall:\", round(recall, 3))\n",
    "print(\"Precision:\", round(precision, 3))\n",
    "print(\"F1 Score:\", round(f1score, 3))\n",
    "print(\"AUC:\", round(auc, 3))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}