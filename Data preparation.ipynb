{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Data description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from JoinDatasets import *\n",
    "main_dir = \"./data\"\n",
    "output_dir = \"./merged-data\"\n",
    "join_data_sets(main_dir, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Dataset content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to count the number of files in a directory\n",
    "def count_files(directory):\n",
    "    \"\"\"\n",
    "    Count files in the given directory.\n",
    "\n",
    "    :param directory: directory to analyse\n",
    "    :return: number of files in the given directory\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for filename in os.listdir(directory):\n",
    "        if os.path.isfile(os.path.join(directory, filename)):\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "plots_saving_dir = \"saved-plots/\"\n",
    "\n",
    "# Count images in each folder\n",
    "healthy_count = count_files(output_dir + \"/Healthy\")\n",
    "powdery_count = count_files(output_dir + \"/Powdery\")\n",
    "rust_count = count_files(output_dir + \"/Rust\")\n",
    "\n",
    "# Create a bar chart\n",
    "labels = ['Healthy', 'Powdery', 'Rust']\n",
    "counts = [healthy_count, powdery_count, rust_count]\n",
    "\n",
    "plt.bar(labels, counts)\n",
    "plt.xlabel('Categories')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Number of Images in Each Category')\n",
    "plt.savefig(plots_saving_dir+'Number_of_Images_in_Each_Category.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Calculate total count\n",
    "total_count = healthy_count + powdery_count + rust_count\n",
    "\n",
    "# Calculate percentages\n",
    "healthy_percentage = (healthy_count / total_count) * 100\n",
    "powdery_percentage = (powdery_count / total_count) * 100\n",
    "rust_percentage = (rust_count / total_count) * 100\n",
    "\n",
    "# Create a pie chart\n",
    "labels = ['Healthy', 'Powdery', 'Rust']\n",
    "sizes = [healthy_percentage, powdery_percentage, rust_percentage]\n",
    "colors = ['lightgreen', 'lightblue', 'lightcoral']\n",
    "\n",
    "plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140)\n",
    "plt.axis('equal')\n",
    "plt.title('Percentage of Images of Each Category in the Dataset')\n",
    "plt.savefig(plots_saving_dir+'Percentage_of_Images_of_Each_Category_in_the_Dataset.png', bbox_inches='tight')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Data relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Errors and noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Data difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Data representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Data normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 12499.42it/s]\n",
      "100%|██████████| 458/458 [00:10<00:00, 44.02it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 6663.97it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 12500.16it/s]\n",
      "100%|██████████| 430/430 [00:10<00:00, 39.94it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 9995.96it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 16661.25it/s]\n",
      "100%|██████████| 434/434 [00:09<00:00, 47.61it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 6667.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished copying\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 16657.28it/s]\n",
      "100%|██████████| 458/458 [00:25<00:00, 17.70it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 6665.03it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 12497.93it/s]\n",
      "100%|██████████| 430/430 [00:21<00:00, 19.63it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 3998.00it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 16653.32it/s]\n",
      "100%|██████████| 434/434 [00:23<00:00, 18.25it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 4001.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished cropping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 16678.48it/s]\n",
      "100%|██████████| 458/458 [04:07<00:00,  1.85it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 4002.20it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 16654.64it/s]\n",
      "100%|██████████| 430/430 [03:49<00:00,  1.88it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 5001.85it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 12495.69it/s]\n",
      "100%|██████████| 434/434 [04:04<00:00,  1.77it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 5000.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished resizing\n"
     ]
    }
   ],
   "source": [
    "from JoinDatasets import join_datasets_with_shape_normalisation\n",
    "import os\n",
    "\n",
    "path = os.getcwd()\n",
    "join_datasets_with_shape_normalisation(os.path.join(path,\"data\"), os.path.join(path,\"merged-data\",\"unchanged\"), \"unchanged\")\n",
    "print(\"Finished copying\")\n",
    "join_datasets_with_shape_normalisation(os.path.join(path,\"data\"), os.path.join(path,\"merged-data\",\"cropped\"), \"crop\", (2421,1728)) # 2592,1728\n",
    "print(\"Finished cropping\")\n",
    "join_datasets_with_shape_normalisation(os.path.join(path,\"data\"), os.path.join(path,\"merged-data\",\"resized\"), \"resize\", (3982,2700))\n",
    "print(\"Finished resizing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing images in 'Healthy' folder...\n",
      "Processing images in 'Powdery' folder...\n",
      "Processing images in 'Rust' folder...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from skimage import exposure\n",
    "from skimage import io\n",
    "import os\n",
    "from scipy import ndimage\n",
    "\n",
    "def better_contrast(original_image, saving_dir, new_name):\n",
    "    v_min, v_max = np.percentile(original_image, (0.2, 99.8))\n",
    "    better_contrast = exposure.rescale_intensity(original_image, in_range=(v_min, v_max))\n",
    "\n",
    "    new_filename = saving_dir + new_name + '.jpg'\n",
    "    io.imsave(fname=new_filename, arr=better_contrast)\n",
    "\n",
    "def gamma_correction(original_image, saving_dir, new_name):\n",
    "    adjusted_gamma_image = exposure.adjust_gamma(original_image, gamma=0.4, gain=0.9)\n",
    "    new_filename = saving_dir + new_name + '.jpg'\n",
    "    io.imsave(fname=new_filename, arr=adjusted_gamma_image)\n",
    "\n",
    "def log_correction(original_image, saving_dir, new_name):\n",
    "    log_correction_image = exposure.adjust_log(original_image)\n",
    "    new_filename = saving_dir + new_name + '.jpg'\n",
    "    io.imsave(fname=new_filename, arr=log_correction_image)\n",
    "\n",
    "def sigmoid_correction(original_image, saving_dir, new_name):\n",
    "    sigmoid_correction_image = exposure.adjust_sigmoid(original_image)\n",
    "    new_filename = saving_dir + new_name + '.jpg'\n",
    "    io.imsave(fname=new_filename, arr=sigmoid_correction_image)\n",
    "\n",
    "def horizontal_flip(original_image, saving_dir, new_name):\n",
    "    horizontal_flip = original_image[:, ::-1]\n",
    "    new_filename = saving_dir + new_name + '.jpg'\n",
    "    io.imsave(fname=new_filename, arr=horizontal_flip)\n",
    "\n",
    "def vertical_flip(original_image, saving_dir, new_name):\n",
    "    vertical_flip = original_image[::-1, :]\n",
    "    new_filename = saving_dir + new_name + '.jpg'\n",
    "    io.imsave(fname=new_filename, arr=vertical_flip)\n",
    "\n",
    "def blured(original_image, saving_dir, new_name):\n",
    "    blured_image = ndimage.uniform_filter(original_image, size=(11, 11, 1))\n",
    "    new_filename = saving_dir + new_name + '.jpg'\n",
    "    io.imsave(fname=new_filename, arr=blured_image)\n",
    "\n",
    "def save_original(original_image, saving_dir, new_name):\n",
    "    new_filename = saving_dir + new_name + '.jpg'\n",
    "    io.imsave(fname=new_filename, arr=original_image)\n",
    "\n",
    "\n",
    "input_folder = 'merged-data/resized'\n",
    "output_dir = 'augmented-data/'\n",
    "\n",
    "for subfolder in os.listdir(input_folder):\n",
    "    subfolder_path = os.path.join(input_folder, subfolder)\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        print(f\"Processing images in '{subfolder}' folder...\")\n",
    "\n",
    "        # Iterate through each image file in the subfolder\n",
    "        for filename in os.listdir(subfolder_path):\n",
    "            if filename.endswith('.jpg') or filename.endswith('.jpeg') or filename.endswith('.png'):\n",
    "\n",
    "                image_path = os.path.join(subfolder_path, filename)\n",
    "\n",
    "                original_image = io.imread(image_path)\n",
    "                saving_dir = output_dir + subfolder + '/' + filename.split('.')[0]\n",
    "\n",
    "                save_original(original_image, saving_dir, '_original')\n",
    "                better_contrast(original_image, saving_dir, '_contrast')\n",
    "                gamma_correction(original_image, saving_dir, '_gamma')\n",
    "                log_correction(original_image, saving_dir, '_log')\n",
    "                sigmoid_correction(original_image, saving_dir, '_sigmoid')\n",
    "                horizontal_flip(original_image, saving_dir, '_horizontal')\n",
    "                vertical_flip(original_image, saving_dir, '_vertical')\n",
    "                blured(original_image, saving_dir, '_blured')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from copytools import *\n",
    "\n",
    "# PROPORTIONS\n",
    "TRAIN = 0.8\n",
    "VAL = 0.1\n",
    "TEST = 0.1\n",
    "\n",
    "merged_data_dir = \"merged-data\"\n",
    "augmented_data_dir = \"augmented-data\"\n",
    "\n",
    "healthy_dir = \"Healthy\"\n",
    "powdery_dir = \"Powdery\"\n",
    "rust_dir = \"Rust\"\n",
    "# images_directories = [healthy_dir, powdery_dir, rust_dir]\n",
    "images_directories = [healthy_dir, powdery_dir, rust_dir]\n",
    "all_splits_dir = \"splits\"\n",
    "train_dir = \"train\"\n",
    "val_dir = \"val\"\n",
    "test_dir = \"test\"\n",
    "\n",
    "# split 1\n",
    "for directory in images_directories:\n",
    "    directory_path = f\"{merged_data_dir}\\\\{directory}\"\n",
    "    files = os.listdir(directory_path)\n",
    "    train_count = round(len(files) * TRAIN)\n",
    "    val_count = round(len(files) * VAL)\n",
    "    test_count = round(len(files) * TEST)\n",
    "    for filename in files:        \n",
    "        if filename.endswith('.jpg') or filename.endswith('.jpeg') or filename.endswith('.png'):\n",
    "            image_path = os.path.join(directory_path, filename)\n",
    "            if train_count != 0:\n",
    "                os.makedirs(os.path.dirname(f\"{all_splits_dir}\\\\split1\\\\{train_dir}\\\\{directory}\\\\\"), exist_ok=True)\n",
    "                destination = f\"{all_splits_dir}\\\\split1\\\\{train_dir}\\\\{directory}\\\\{filename}\"\n",
    "                shutil.copyfile(image_path, destination)\n",
    "                train_count -= 1\n",
    "            elif val_count != 0:\n",
    "                os.makedirs(os.path.dirname(f\"{all_splits_dir}\\\\split1\\\\{val_dir}\\\\{directory}\\\\\"), exist_ok=True)\n",
    "                destination = f\"{all_splits_dir}\\\\split1\\\\{val_dir}\\\\{directory}\\\\{filename}\"\n",
    "                shutil.copyfile(image_path, destination)\n",
    "                val_count -= 1\n",
    "            elif test_count != 0:\n",
    "                os.makedirs(os.path.dirname(f\"{all_splits_dir}\\\\split1\\\\{test_dir}\\\\{directory}\\\\\"), exist_ok=True)\n",
    "                destination = f\"{all_splits_dir}\\\\split1\\\\{test_dir}\\\\{directory}\\\\{filename}\"\n",
    "                shutil.copyfile(image_path, destination)\n",
    "                test_count -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split 2 - resized -> augmented -> splited            \n",
    "for directory in images_directories:\n",
    "    directory_path = f\"{augmented_data_dir}\\\\{directory}\"\n",
    "    files = os.listdir(directory_path)\n",
    "    train_count = round(len(files) * TRAIN)\n",
    "    val_count = round(len(files) * VAL)\n",
    "    test_count = round(len(files) * TEST)\n",
    "    for filename in files:        \n",
    "        if filename.endswith('.jpg') or filename.endswith('.jpeg') or filename.endswith('.png'):\n",
    "            image_path = os.path.join(directory_path, filename)\n",
    "            if train_count != 0:\n",
    "                os.makedirs(os.path.dirname(f\"{all_splits_dir}\\\\split2\\\\{train_dir}\\\\{directory}\\\\{filename}\"), exist_ok=True)\n",
    "                destination = f\"{all_splits_dir}\\\\split2\\\\{train_dir}\\\\{directory}\\\\{filename}\"\n",
    "                shutil.copyfile(image_path, destination)\n",
    "                train_count -= 1\n",
    "            elif val_count != 0:\n",
    "                os.makedirs(os.path.dirname(f\"{all_splits_dir}\\\\split2\\\\{val_dir}\\\\{directory}\\\\{filename}\"), exist_ok=True)\n",
    "                destination = f\"{all_splits_dir}\\\\split2\\\\{val_dir}\\\\{directory}\\\\{filename}\"\n",
    "                shutil.copyfile(image_path, destination)\n",
    "                val_count -= 1\n",
    "            elif test_count != 0:\n",
    "                os.makedirs(os.path.dirname(f\"{all_splits_dir}\\\\split2\\\\{test_dir}\\\\{directory}\\\\\"), exist_ok=True)\n",
    "                destination = f\"{all_splits_dir}\\\\split2\\\\{test_dir}\\\\{directory}\\\\{filename}\"\n",
    "                shutil.copyfile(image_path, destination)\n",
    "                test_count -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split 3 - copy split 2 without VAL set -> create VAL set from TRAIN subset\n",
    "destination_directory = f\"{all_splits_dir}\\\\split3\"   \n",
    "for directory in [train_dir, test_dir]:\n",
    "    source_directory = f\"{all_splits_dir}\\\\split2\\\\{directory}\"\n",
    "    try:\n",
    "        copytree(source_directory, f\"{destination_directory}\\\\{directory}\")\n",
    "    except:\n",
    "        print(\"directory already exists\")\n",
    "# test,train,valid directory\n",
    "for directory in images_directories:\n",
    "    directory_path = f\"{destination_directory}\\\\{test_dir}\\\\{directory}\"\n",
    "    source_path = f\"{all_splits_dir}\\\\split2\\\\{test_dir}\\\\{directory}\"\n",
    "    files = os.listdir(f\"{source_path}\")\n",
    "    val_count = round(len(files) * VAL)\n",
    "    for filename in files:        \n",
    "        if filename.endswith('.jpg') or filename.endswith('.jpeg') or filename.endswith('.png'):\n",
    "            image_path = os.path.join(directory_path, filename)\n",
    "            if val_count != 0:\n",
    "                os.makedirs(os.path.dirname(f\"{all_splits_dir}\\\\split3\\\\{val_dir}\\\\{directory}\\\\{filename}\"), exist_ok=True)\n",
    "                destination = f\"{all_splits_dir}\\\\split3\\\\{val_dir}\\\\{directory}\\\\{filename}\"\n",
    "                shutil.copyfile(image_path, destination)\n",
    "                val_count -= 1\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
