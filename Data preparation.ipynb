{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Data description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from JoinDatasets import *\n",
    "import shutil\n",
    "import os\n",
    "labels = [\"Healthy\", \"Powdery\", \"Rust\"]\n",
    "sets = [\"Test\", \"Train\", \"Validation\"]\n",
    "\n",
    "def join_data_sets(main_dir, output_dir):\n",
    "    for label in labels:\n",
    "        for set in sets:\n",
    "            dir_path = os.path.join(main_dir, set, set, label)\n",
    "            files = os.listdir(dir_path)\n",
    "            for file in files:\n",
    "                src = os.path.join(dir_path, file)\n",
    "                dst = os.path.join(output_dir, label)\n",
    "                if not os.path.exists(dst):\n",
    "                    os.mkdir(dst)\n",
    "\n",
    "                shutil.copy2(src, dst)\n",
    "\n",
    "main_dir = \"./data\"\n",
    "output_dir = \"./merged-data\"\n",
    "join_data_sets(main_dir, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Dataset content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to count the number of files in a directory\n",
    "def count_files(directory):\n",
    "    \"\"\"\n",
    "    Count files in the given directory.\n",
    "\n",
    "    :param directory: directory to analyse\n",
    "    :return: number of files in the given directory\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for filename in os.listdir(directory):\n",
    "        if os.path.isfile(os.path.join(directory, filename)):\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "plots_saving_dir = \"saved-plots/\"\n",
    "\n",
    "# Count images in each folder\n",
    "healthy_count = count_files(output_dir + \"/Healthy\")\n",
    "powdery_count = count_files(output_dir + \"/Powdery\")\n",
    "rust_count = count_files(output_dir + \"/Rust\")\n",
    "\n",
    "# Create a bar chart\n",
    "labels = ['Healthy', 'Powdery', 'Rust']\n",
    "counts = [healthy_count, powdery_count, rust_count]\n",
    "\n",
    "plt.bar(labels, counts)\n",
    "plt.xlabel('Categories')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Number of Images in Each Category')\n",
    "plt.savefig(plots_saving_dir+'Number_of_Images_in_Each_Category.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Calculate total count\n",
    "total_count = healthy_count + powdery_count + rust_count\n",
    "\n",
    "# Calculate percentages\n",
    "healthy_percentage = (healthy_count / total_count) * 100\n",
    "powdery_percentage = (powdery_count / total_count) * 100\n",
    "rust_percentage = (rust_count / total_count) * 100\n",
    "\n",
    "# Create a pie chart\n",
    "labels = ['Healthy', 'Powdery', 'Rust']\n",
    "sizes = [healthy_percentage, powdery_percentage, rust_percentage]\n",
    "colors = ['lightgreen', 'lightblue', 'lightcoral']\n",
    "\n",
    "plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140)\n",
    "plt.axis('equal')\n",
    "plt.title('Percentage of Images of Each Category in the Dataset')\n",
    "plt.savefig(plots_saving_dir+'Percentage_of_Images_of_Each_Category_in_the_Dataset.png', bbox_inches='tight')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Data relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from rgbMean import *\n",
    "\n",
    "healthy_dir = \"merged-data\\\\Healthy\"\n",
    "powdery_dir = \"merged-data\\\\Powdery\"\n",
    "rusty_dir = \"merged-data\\\\Rust\"\n",
    "directories = [healthy_dir, powdery_dir, rusty_dir]\n",
    "directories_rgb_count = []\n",
    "rgbMean = RgbMean()\n",
    "for directory in directories:\n",
    "    fileNames = os.listdir(directory)\n",
    "    filePaths = [directory + \"\\\\\" + fileName for fileName in fileNames]\n",
    "    with multiprocessing.Pool(4) as pool:\n",
    "        result = pool.map(rgbMean.get_single_image_rgb_mean, filePaths)\n",
    "        rgb_counts = rgbMean.get_rgb_count(result)\n",
    "        directories_rgb_count.append(rgb_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for directory_rgb_count in directories_rgb_count: \n",
    "    plt.xlabel('RGB Value')\n",
    "    plt.ylabel('Count')\n",
    "    plt.plot(directory_rgb_count[0], label = \"R\", color='r')\n",
    "    plt.plot(directory_rgb_count[1], label = \"G\", color='g')\n",
    "    plt.plot(directory_rgb_count[2], label = \"B\", color='b')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "source": [
    "Errors and noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Data difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Data representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Data normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from JoinDatasets import join_datasets_with_shape_normalisation\n",
    "import os\n",
    "\n",
    "path = os.getcwd()\n",
    "join_datasets_with_shape_normalisation(os.path.join(path,\"data\"), os.path.join(path,\"merged-data\",\"unchanged\"), \"unchanged\")\n",
    "print(\"Finished copying\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "join_datasets_with_shape_normalisation(os.path.join(path,\"data\"), os.path.join(path,\"merged-data\",\"cropped\"), \"crop\", (2421,1728)) # 2592,1728\n",
    "print(\"Finished cropping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#join_datasets_with_shape_normalisation(os.path.join(path,\"data\"), os.path.join(path,\"merged-data\",\"resized\"), \"resize\", (3982,2700))\n",
    "join_datasets_with_shape_normalisation(os.path.join(path,\"data\"), os.path.join(path,\"merged-data\",\"resized\"), \"resize\", (225,225))\n",
    "print(\"Finished resizing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import exposure, io\n",
    "import os\n",
    "from scipy import ndimage\n",
    "from multiprocessing import Process\n",
    "\n",
    "def better_contrast(original_image, saving_dir, new_name):\n",
    "    v_min, v_max = np.percentile(original_image, (0.2, 99.8))\n",
    "    better_contrast = exposure.rescale_intensity(original_image, in_range=(v_min, v_max))\n",
    "    save_image(better_contrast, saving_dir, new_name)\n",
    "\n",
    "def gamma_correction(original_image, saving_dir, new_name):\n",
    "    adjusted_gamma_image = exposure.adjust_gamma(original_image, gamma=0.4, gain=0.9)\n",
    "    save_image(adjusted_gamma_image, saving_dir, new_name)\n",
    "\n",
    "def log_correction(original_image, saving_dir, new_name):\n",
    "    log_correction_image = exposure.adjust_log(original_image)\n",
    "    save_image(log_correction_image, saving_dir, new_name)\n",
    "\n",
    "def sigmoid_correction(original_image, saving_dir, new_name):\n",
    "    sigmoid_correction_image = exposure.adjust_sigmoid(original_image)\n",
    "    save_image(sigmoid_correction_image, saving_dir, new_name)\n",
    "\n",
    "def horizontal_flip(original_image, saving_dir, new_name):\n",
    "    horizontal_flip = original_image[:, ::-1]\n",
    "    save_image(horizontal_flip, saving_dir, new_name)\n",
    "\n",
    "def vertical_flip(original_image, saving_dir, new_name):\n",
    "    vertical_flip = original_image[::-1, :]\n",
    "    save_image(vertical_flip, saving_dir, new_name)\n",
    "\n",
    "def blured(original_image, saving_dir, new_name):\n",
    "    blured_image = ndimage.uniform_filter(original_image, size=(11, 11, 1))\n",
    "    save_image(blured_image, saving_dir, new_name)\n",
    "\n",
    "def save_image(image, saving_dir, new_name):\n",
    "    new_filename = saving_dir + new_name + '.jpg'\n",
    "    io.imsave(fname=new_filename, arr=image)\n",
    "\n",
    "def process_image(image_path, saving_dir):\n",
    "    original_image = io.imread(image_path)\n",
    "    save_original(original_image, saving_dir, '_original')\n",
    "    better_contrast(original_image, saving_dir, '_contrast')\n",
    "    gamma_correction(original_image, saving_dir, '_gamma')\n",
    "    log_correction(original_image, saving_dir, '_log')\n",
    "    sigmoid_correction(original_image, saving_dir, '_sigmoid')\n",
    "    horizontal_flip(original_image, saving_dir, '_horizontal')\n",
    "    vertical_flip(original_image, saving_dir, '_vertical')\n",
    "    blured(original_image, saving_dir, '_blured')\n",
    "\n",
    "def save_original(original_image, saving_dir, new_name):\n",
    "    save_image(original_image, saving_dir, new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "input_folder = 'merged-data/resized'\n",
    "output_dir = 'augmented-data/'\n",
    "\n",
    "def process_image_par(subfolder, filename):\n",
    "    image_path = os.path.join(input_folder, subfolder, filename)\n",
    "    original_image = io.imread(image_path)\n",
    "    saving_dir = os.path.join(output_dir, subfolder, filename.split('.')[0])\n",
    "\n",
    "    save_original(original_image, saving_dir, '_original')\n",
    "    better_contrast(original_image, saving_dir, '_contrast')\n",
    "    gamma_correction(original_image, saving_dir, '_gamma')\n",
    "    log_correction(original_image, saving_dir, '_log')\n",
    "    sigmoid_correction(original_image, saving_dir, '_sigmoid')\n",
    "    horizontal_flip(original_image, saving_dir, '_horizontal')\n",
    "    vertical_flip(original_image, saving_dir, '_vertical')\n",
    "    blured(original_image, saving_dir, '_blurred')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create output directories if they don't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for subfolder in os.listdir(input_folder):\n",
    "        subfolder_path = os.path.join(input_folder, subfolder)\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            print(f\"Processing images in '{subfolder}' folder...\")\n",
    "\n",
    "            # Parallelize the processing of images within each subfolder\n",
    "            Parallel(n_jobs=8)(\n",
    "                delayed(process_image_par)(subfolder, filename)\n",
    "                for filename in os.listdir(subfolder_path)\n",
    "                if filename.endswith('.jpg') or filename.endswith('.jpeg') or filename.endswith('.png')\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from copytools import *\n",
    "\n",
    "# PROPORTIONS\n",
    "TRAIN = 0.8\n",
    "VAL = 0.1\n",
    "TEST = 0.1\n",
    "\n",
    "merged_data_dir = \"merged-data/resized\"\n",
    "augmented_data_dir = \"augmented-data\"\n",
    "\n",
    "healthy_dir = \"Healthy\"\n",
    "powdery_dir = \"Powdery\"\n",
    "rust_dir = \"Rust\"\n",
    "# images_directories = [healthy_dir, powdery_dir, rust_dir]\n",
    "images_directories = [healthy_dir, powdery_dir, rust_dir]\n",
    "all_splits_dir = \"splits\"\n",
    "train_dir = \"train\"\n",
    "val_dir = \"val\"\n",
    "test_dir = \"test\"\n",
    "\n",
    "# split 1\n",
    "for directory in images_directories:\n",
    "    directory_path = f\"{merged_data_dir}/{directory}\"\n",
    "    files = os.listdir(directory_path)\n",
    "    train_count = round(len(files) * TRAIN)\n",
    "    val_count = round(len(files) * VAL)\n",
    "    test_count = round(len(files) * TEST)\n",
    "    for filename in files:        \n",
    "        if filename.endswith('.jpg') or filename.endswith('.jpeg') or filename.endswith('.png'):\n",
    "            image_path = os.path.join(directory_path, filename)\n",
    "            if train_count != 0:\n",
    "                os.makedirs(os.path.dirname(f\"{all_splits_dir}/split1/{train_dir}/{directory}/\"), exist_ok=True)\n",
    "                destination = f\"{all_splits_dir}/split1/{train_dir}/{directory}/{filename}\"\n",
    "                shutil.copyfile(image_path, destination)\n",
    "                train_count -= 1\n",
    "            elif val_count != 0:\n",
    "                os.makedirs(os.path.dirname(f\"{all_splits_dir}/split1/{val_dir}/{directory}/\"), exist_ok=True)\n",
    "                destination = f\"{all_splits_dir}/split1/{val_dir}/{directory}/{filename}\"\n",
    "                shutil.copyfile(image_path, destination)\n",
    "                val_count -= 1\n",
    "            elif test_count != 0:\n",
    "                os.makedirs(os.path.dirname(f\"{all_splits_dir}/split1/{test_dir}/{directory}/\"), exist_ok=True)\n",
    "                destination = f\"{all_splits_dir}/split1/{test_dir}/{directory}/{filename}\"\n",
    "                shutil.copyfile(image_path, destination)\n",
    "                test_count -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split 2 - resized -> augmented -> splited            \n",
    "for directory in images_directories:\n",
    "    directory_path = f\"{augmented_data_dir}/{directory}\"\n",
    "    files = os.listdir(directory_path)\n",
    "    train_count = round(len(files) * TRAIN)\n",
    "    val_count = round(len(files) * VAL)\n",
    "    test_count = round(len(files) * TEST)\n",
    "    for filename in files:        \n",
    "        if filename.endswith('.jpg') or filename.endswith('.jpeg') or filename.endswith('.png'):\n",
    "            image_path = os.path.join(directory_path, filename)\n",
    "            if train_count != 0:\n",
    "                os.makedirs(os.path.dirname(f\"{all_splits_dir}/split2/{train_dir}/{directory}/{filename}\"), exist_ok=True)\n",
    "                destination = f\"{all_splits_dir}/split2/{train_dir}/{directory}/{filename}\"\n",
    "                shutil.copyfile(image_path, destination)\n",
    "                train_count -= 1\n",
    "            elif val_count != 0:\n",
    "                os.makedirs(os.path.dirname(f\"{all_splits_dir}/split2/{val_dir}/{directory}/{filename}\"), exist_ok=True)\n",
    "                destination = f\"{all_splits_dir}/split2/{val_dir}/{directory}/{filename}\"\n",
    "                shutil.copyfile(image_path, destination)\n",
    "                val_count -= 1\n",
    "            elif test_count != 0:\n",
    "                os.makedirs(os.path.dirname(f\"{all_splits_dir}/split2/{test_dir}/{directory}/\"), exist_ok=True)\n",
    "                destination = f\"{all_splits_dir}/split2/{test_dir}/{directory}/{filename}\"\n",
    "                shutil.copyfile(image_path, destination)\n",
    "                test_count -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# split 3 - copy split 2 without VAL set -> create VAL set from TRAIN subset\n",
    "import random\n",
    "\n",
    "\n",
    "destination_directory = f\"{all_splits_dir}/split3\"\n",
    "for directory in [train_dir, test_dir]:\n",
    "    source_directory = f\"{all_splits_dir}/split2/{directory}\"\n",
    "    try:\n",
    "        copytree(source_directory, f\"{destination_directory}/{directory}\")\n",
    "    except:\n",
    "        print(\"directory already exists\")\n",
    "# test,train,valid directory\n",
    "for directory in images_directories:\n",
    "    directory_path = f\"{destination_directory}/{train_dir}/{directory}\"\n",
    "    source_path = f\"{all_splits_dir}/split2/{train_dir}/{directory}\"\n",
    "    files = os.listdir(f\"{source_path}\")\n",
    "    val_count = round(len(files) * VAL)\n",
    "    random.shuffle(files)\n",
    "    for filename in files:        \n",
    "        if filename.endswith('.jpg') or filename.endswith('.jpeg') or filename.endswith('.png'):\n",
    "            image_path = os.path.join(directory_path, filename)\n",
    "            if val_count != 0:\n",
    "                os.makedirs(os.path.dirname(f\"{all_splits_dir}/split3/{val_dir}/{directory}/{filename}\"), exist_ok=True)\n",
    "                destination = f\"{all_splits_dir}/split3/{val_dir}/{directory}/{filename}\"\n",
    "                shutil.copyfile(image_path, destination)\n",
    "                val_count -= 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
